# ğŸŒ Website Availability Checker

## ğŸ“– Overview
The **Website Availability Checker** is a Python-based tool designed to monitor the uptime of websites. It checks the availability of specified URLs, alerts the user if a website is down, and logs the results for better monitoring. ğŸš€

---

## ğŸ¯ Features
- âœ… **Website Monitoring**: Checks the availability of multiple websites.
- ğŸ”” **Desktop Notifications**: Alerts users when a website is down.
- ğŸ“Š **HTTP Status Codes**: Verifies the HTTP response code of websites.
- ğŸ”„ **Periodic Monitoring**: Performs checks at regular intervals.
- ğŸ’¡ **Error Handling**: Handles network errors gracefully.

---

## ğŸ› ï¸ Requirements
Make sure you have the following installed:

- Python 3.8 or higher ğŸ
- Required Python libraries:
  ```bash
  pip install requests plyer
  ```

---

## ğŸš€ Usage

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/your-username/website-availability-checker.git
   cd website-availability-checker
   ```

2. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the Script**:
   ```bash
   python website_checker.py
   ```

4. **Add Websites to Monitor**:
   - Edit the `websites` list in the `website_checker.py` file:
     ```python
     websites = [
         "https://example.com",
         "https://google.com",
         "https://nonexistentwebsite.com"
     ]
     ```

5. **Set the Check Interval**:
   - Adjust the `check_interval` variable to define how frequently (in seconds) websites should be checked:
     ```python
     check_interval = 60  # Check every 60 seconds
     ```

---

## ğŸ“ Example Output
```
Starting Website Availability Checker... ğŸ•µï¸
âœ… https://example.com is up!
âœ… https://google.com is up!
âŒ Error checking https://nonexistentwebsite.com: HTTPSConnectionPool(host='nonexistentwebsite.com', port=443): Max retries exceeded.
â³ Waiting 60 seconds before the next check...
```

---

## ğŸ“š How It Works
1. The script uses the `requests` module to send HTTP GET requests to the specified websites.
2. If the website is reachable (`status_code == 200`), it logs a success message.
3. If the website is down or an error occurs, it logs an error and sends a desktop notification via the `plyer` library.
4. The process repeats at regular intervals defined by `check_interval`.

---

## ğŸ’¡ Future Enhancements
- ğŸŒŸ Add email alerts for downtime notifications.
- ğŸŒŸ Implement a graphical user interface (GUI) using `tkinter`.
- ğŸŒŸ Log status changes to a file for historical analysis.
- ğŸŒŸ Add concurrency to monitor multiple websites simultaneously.

---

## ğŸ§  Skills Learned
- HTTP requests using Python's `requests` module.
- Exception handling in Python.
- Scheduling tasks using loops and delays.
- Sending desktop notifications using the `plyer` library.

---

## ğŸ¤ Contributing
Contributions are welcome! Feel free to submit a pull request or open an issue to discuss potential improvements. ğŸ™Œ

---

## ğŸ“„ License
This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## ğŸ™Œ Acknowledgments
- [Python Requests Library](https://docs.python-requests.org/en/latest/)
- [Plyer Notifications](https://plyer.readthedocs.io/en/latest/)

---

## ğŸ”— Connect
For any queries or feedback, feel free to reach out:
- ğŸŒ [GitHub](https://github.com/AkshayKondke)
- âœ‰ï¸ [Email](mailto:akshay.kondke999@gmail.com)
- ğŸ”— [LinkedIn](https://www.linkedin.com/in/akshay-kondke-12b07a246)

Happy Monitoring! ğŸš€

